"""
#! Algorithme par L√©on Dalle - 06/03/2024
#? Utilisation de certaines portions de codes qui √©taient fournies via BoostCamp (Auteur pr√©sum√© : Romaric Sichler)

#*Nota Bene : Le code fonctionne bien pour la d√©tection des fl√®ches, quasi tout les essais sont concluants (Aruco 13)
#*            Mais la d√©tection de l'Aruco 8 pour les rectangles de couleur est beaucoup plus al√©atoire, surtout s'il faut rep√©rer 3 arucos sur une m√™me frame.
#*            Possibilit√© de changer l'aruco par un autre plus facilement d√©tectable ?

Concevez un algorithme qui :
- prend une photo depuis la webcam de l‚Äôordinateur
- trouve 4 ARuco avec le m√™me identifiant dans l‚Äôimage, sinon renvoie une erreur
- d√©forme l‚Äôimage pour ne travailler que dans la zone d‚Äôint√©r√™t d√©finie par ces 4 marqueurs
- trouve le sens d‚Äôune contenue dans la zone d√©finie et l‚Äôaffiche en console
- vous pouvez utiliser des affichages graphiques pour que les √©ventuelles erreurs du programme soient transparentes
"""

import numpy as np
import sys
import cv2
import time

def trouver_fleche_et_son_sens():
    img = cv2.imread('image_zoomee.png')

    #r√©duisons le bruit en utilisant un flou gaussien
    img = cv2.GaussianBlur(img, (11,11), 0)
    #On travaille sur une image en niveau de gris
    img_gris = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    #on calcule les sommets avec une fonction bien pratique d'openCV, en prenant les 7 meilleurs sommets d'une √©ventuelle figure
    sommets = np.intp(cv2.goodFeaturesToTrack(img_gris,7,0.01,10))
    if sommets is None:
        print("üö´ Erreur : pas de sommets d√©tect√©s !")
        exit()


    #rendu visuel pour d√©bugger
    for i,vals in enumerate(sommets):
        x,y = vals.ravel()
        cv2.circle(img,(x,y),3,(255,255,0),-1)
        cv2.putText(img, str(i), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA )
    #on prends les sommets les plus √©loign√©s
    xmax, ymax = (np.max(sommets, axis = 0)).ravel()
    xmin, ymin = (np.min(sommets, axis = 0)).ravel() 

    #d√©terminons l'axe du milieu de notre fl√®che, puis tra√ßons le visuellemet (cv2.line)
    xmil=int(xmin+((xmax-xmin)/2))
    cv2.line(img,(xmil,0),(xmil,img.shape[0]),(255,0,0),2)

    #au vu de la forme de notre fl√®che le nombre de sommmets le plus grand est dans la partie "pointe" notre fl√®che
    nbSommetsDroite=np.count_nonzero(sommets[:,0,0]>xmil)
    nbSommetsGauche=np.count_nonzero(sommets[:,0,0]<xmil)

    print("üéØ Fl√®che d√©tect√©e ! Son sens est √† ", end="")
    #on finit par afficher le sens de notre fl√®che
    if nbSommetsDroite>nbSommetsGauche:
        print('Droite')
    else:
        print('Gauche')


    #les prochaines lignes ne servent qu'√† l'affichage graphique
    cv2.imshow('Fl√®che trouv√©e !',img)
    cv2.waitKey(0)

def chiffre():
    image = cv2.imread("image_zoomee.png")
    
    #Dictionnaire de correspondance
    correspondances = {
        (1, 1, 1, 0, 1, 1, 1): 0,
        (0, 0, 1, 0, 0, 1, 0): 1,
        (1, 0, 1, 1, 1, 0, 1): 2,
        (1, 0, 1, 1, 0, 1, 1): 3,
        (0, 1, 1, 1, 0, 1, 0): 4,
        (1, 1, 0, 1, 0, 1, 1):5,
        (1, 1, 0, 1, 1, 1, 1):6,
        (1, 0, 1, 0, 0, 1, 0):7,
        (1, 1, 1, 1, 1, 1, 1):8,
        (1, 1, 1, 1, 0, 1, 1):9
    }

    (H, L) = image.shape[:2] #r√©cup√©rer la hauteur et largeur de l'image

    # 7 zones d'int√©r√™t √† scanner
    segments = [
        ((int(L/4), 0), (int(L*3/4), int(H/6))),                # haut
        ((0, int(H/6)), (int(L/4), int(H/2))),                  # haut-gauche
        ((int(L*3/4), int(H/6)), (int(L), int(H/2))),           # haut-droite
        ((int(L/4), int(H*2/5)) , (int(L*3/4), int(H*3/5))),    # centre
        ((0, int(H/2)), (int(L/4), int(H*4/5))),                # bas-gauche
        ((int(L*3/4),int(H/2)),(int(L),int(H*5/6))),            # bas-droite
        ((int(L/4), int(H*5/6)), (int(L*3/4), int(H)))          # bas
    ]

    for rect in segments:
        color=tuple(np.random.random(size=3) * 256)
        image=cv2.rectangle(image, rect[0], rect[1],color, 3)

    #passer en niveau de gris
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    #d√©finir un seuil et binariser l'image
    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]
    #nettoyer l'image avec un morphose (optionnel)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 5))
    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)

    #cr√©er un tableau des √©tats vus des segments (1 le segment est noir, 0 le segment est blanc)
    on = [0] * len(segments) 

    #voir l'√©tat pour chaque segment :
    for (i, ((xA, yA), (xB, yB))) in enumerate(segments):
        # extraire une image binaire de la zone d'int√©r√™t correspondant au segment
        segROI = thresh[yA:yB, xA:xB]
        #compter le nombre de pixel noir
        nbpixels = cv2.countNonZero(segROI)
        #calculer l'aire du segment
        area = (xB - xA) * (yB - yA)
        # modifier le tableau d'√©tat vu si le nombre de pixels noir d√©passe 30% (√† affiner en fonction de vos cam√©ras)
        if nbpixels / float(area) > 0.3:
            on[i]= 1

    #Afficher une croix au centre des segments identifi√©s
    for i in range(len(on)):
        if on[i]==1:
            milsegement=(int((segments[i][0][0]+segments[i][1][0])/2),int((segments[i][0][1]+segments[i][1][1])/2))
            cv2.putText(image, str("X"), milsegement, cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

    #finalement on va chercher dans le dictinnaire du d√©but quel est le chiffre lu
    if tuple(on) not in correspondances:
        print("üö´ Aucun chiffre trouv√©")
        print("On a tent√© de rechercher le chiffre : ",on)
    else:
        nombrelu = correspondances[tuple(on)]
        print("‚úÖ On a trouv√© le chiffre : ", nombrelu)
    cv2.imshow('Zones trouv√©es', image)  
    cv2.waitKey(0)

try:
    #! Prendre une photo depuis la webcam
    camera = cv2.VideoCapture(0)
    x, image = camera.read()
    cv2.imwrite('opencv1.png', image)

    #?Test
    #image = cv2.imread('Cours1 S2-20240228\\flecheAR.jpg')
    
    #!trouve 4 ARuco avec le m√™me identifiant dans l‚Äôimage, sinon renvoie une erreur
    dictionnaire = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)
    parametres =  cv2.aruco.DetectorParameters()
    coinsMarqueurs, idsMarqueur, PotentielsMarqueurs = cv2.aruco.ArucoDetector(dictionnaire, parametres).detectMarkers(cv2.imread('opencv1.png'))

    print("üì° Recherche des 4 ARuco avec le m√™me identifiant ...")
    animation = "|||||/////-----\\\\\\"
    i = 0
    while True:
        if idsMarqueur is not None and len(coinsMarqueurs) == 4 and len(set(idsMarqueur.flatten())) == 1:
            cv2.imwrite('opencv1.png', image)
            break

        x, image = camera.read()
        coinsMarqueurs, idsMarqueur, PotentielsMarqueurs = cv2.aruco.ArucoDetector(dictionnaire, parametres).detectMarkers(image)
        

        # Arr√™t au bout de 10 secondes sans d√©tection (une boucle dure environ 0.03s, donc 333 boucles ~= 10s)
        if i == 333:
            print("üö´ Erreur : pas assez d'arucos d√©tect√©s ou de m√™me identifiant ! (Delay10sOutofBounds)")
            exit()

        # Print the animation
        print(animation[i % len(animation)], end="\r")
        i += 1
        sys.stdout.flush()
        time.sleep(0.01)
    print('\r' + ' ' * len(animation) + '\r', end='')
    print("‚úÖ 4 Arucos avec le m√™me identifiant trouv√©s !")



    #? Afficher les coins des arucos d√©tect√©s
    ids = idsMarqueur.flatten()	
    image = cv2.imread('opencv1.png')
    tous_coins = []
    for (coinMarqueur, idMarqueur) in zip(coinsMarqueurs, ids):
        # extraire les angles des aruco (toujours dans l'ordre haut-gauche, haut-droite, bas-gauche, bas-droit)
        coins = coinMarqueur.reshape((4, 2))
        (topLeft, topRight, bottomRight, bottomLeft) = coins
        # convertir en entier (pour l'affichage)
        topRight = (int(topRight[0]), int(topRight[1]))
        bottomRight = (int(bottomRight[0]), int(bottomRight[1]))
        bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))
        topLeft = (int(topLeft[0]), int(topLeft[1]))
        
        # dessiner un quadrilat√®re autour de chaque aruco
        cv2.line(image, topLeft, topRight, (0, 255, 0), 2)
        cv2.line(image, topRight, bottomRight, (0, 255, 0), 2)
        cv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)
        cv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)
        # calculer puis afficher un point rouge au centre
        cX = int((topLeft[0] + bottomRight[0]) / 2.0)
        cY = int((topLeft[1] + bottomRight[1]) / 2.0)
        cv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)
        # affiher l'identifiant
        cv2.putText(image, str(idMarqueur),
            (topLeft[0], topLeft[1] - 15), cv2.FONT_HERSHEY_SIMPLEX,
            0.5, (0, 255, 0), 2)
        
        tous_coins.append(coins)
        
    # afficher l'image
    cv2.imshow("D√©tection des arucos sur l'image", image)
    cv2.waitKey(0)

    #! D√©former l‚Äôimage pour ne travailler que dans la zone d‚Äôint√©r√™t d√©finie par ces 4 marqueurs
    print("üîç On zoom sur l'image dans la zone des 4 marqueurs")
    image = cv2.imread('opencv1.png')
    tous_coins = np.concatenate(tous_coins)
    # On calcule les coordonn√©es des coins de l'image zoom√©e
    top_left = np.min(tous_coins, axis=0)
    bottom_right = np.max(tous_coins, axis=0)
    top_right = np.array([bottom_right[0], top_left[1]])
    bottom_left = np.array([top_left[0], bottom_right[1]])

    # On sp√©cifie les coordonn√©es des coins de l'image zoom√©e, +30 Pixels pour enlever les arucos de la zone et ainsi √©viter les erreurs avec GoodFeaturesToTrack
    offset = 20
    points1 = np.float32([top_left + [offset, offset], top_right + [-offset, offset], bottom_right + [-offset, -offset], bottom_left + [offset, -offset]])
    points2 = np.float32([[0, 0], [200, 0], [200, 200], [0, 200]])

    # On calcule la matrice de transformation
    vecttrans = cv2.getPerspectiveTransform(points1, points2)

    #! On applique la transformation √† l'image d'origine
    image_zoomee = cv2.warpPerspective(image, vecttrans, (200, 200))

    # On affiche l'image zoom√©e
    cv2.imshow("Zoom sur la zone", image_zoomee)
    cv2.imwrite('image_zoomee.png', image_zoomee)
    cv2.waitKey(0)

    #! Recherche d'une fl√®che dans l'image zoom√©e et d√©termination de son sens
    if idsMarqueur[0] == 13: #? L'ID de la fl√®che est 13
        print("üîç On recherche une fl√®che dans l'image zoom√©e")
        trouver_fleche_et_son_sens()
    elif idsMarqueur[0] == 8: #? L'ID des rectangles de couleur est 8
        print("ü§î Il devrait y avoir un rectangle de couleur dans la zone zoom√©e")
    elif idsMarqueur[0] == 9:
        print("üî¢ On va essayer de voir si y'a un chiffre dans l'image")
        chiffre()
    else:
        print("üö´ Rien de connu n'a √©t√© d√©tect√©...")
        
except Exception as e:
    print("üö´ Erreur :", e)