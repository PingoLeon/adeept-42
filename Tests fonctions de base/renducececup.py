"""
#! Algorithme par L√©on Dalle - 06/03/2024
#? Utilisation de certaines portions de codes qui √©taient fournies via BoostCamp (Auteur pr√©sum√© : Romaric Sichler)

Concevez un algorithme qui :
- prend une photo depuis la webcam de l‚Äôordinateur
- trouve 4 ARuco avec le m√™me identifiant dans l‚Äôimage, sinon renvoie une erreur
- d√©forme l‚Äôimage pour ne travailler que dans la zone d‚Äôint√©r√™t d√©finie par ces 4 marqueurs
- trouve le sens d‚Äôune contenue dans la zone d√©finie et l‚Äôaffiche en console
- vous pouvez utiliser des affichages graphiques pour que les √©ventuelles erreurs du programme soient transparentes
"""

import numpy as np
import sys
import cv2
import time

def trouver_fleche_et_son_sens():
    img = cv2.imread('image_zoomee.png')

    #r√©duisons le bruit en utilisant un flou gaussien
    img = cv2.GaussianBlur(img, (11,11), 0)
    #On travaille sur une image en niveau de gris
    img_gris = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    #on calcule les sommets avec une fonction bien pratique d'openCV, en prenant les 7 meilleurs sommets d'une √©ventuelle figure
    sommets = np.intp(cv2.goodFeaturesToTrack(img_gris,7,0.01,10))
    if sommets is None:
        print("üö´ Erreur : pas de sommets d√©tect√©s !")
        exit()


    #rendu visuel pour d√©bugger
    for i,vals in enumerate(sommets):
        x,y = vals.ravel()
        cv2.circle(img,(x,y),3,(255,255,0),-1)
        cv2.putText(img, str(i), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2, cv2.LINE_AA )

    #on prends les sommets les plus √©loign√©s
    xmax, ymax = (np.max(sommets, axis = 0)).ravel()
    xmin, ymin = (np.min(sommets, axis = 0)).ravel() 

    #d√©terminons l'axe du milieu de notre fl√®che, puis tra√ßons le visuellemet (cv2.line)
    xmil=int(xmin+((xmax-xmin)/2))
    cv2.line(img,(xmil,0),(xmil,img.shape[0]),(255,0,0),2)

    #au vu de la forme de notre fl√®che le nombre de sommmets le plus grand est dans la partie "pointe" notre fl√®che
    nbSommetsDroite=np.count_nonzero(sommets[:,0,0]>xmil)
    nbSommetsGauche=np.count_nonzero(sommets[:,0,0]<xmil)

    print("üéØ Fl√®che d√©tect√©e ! Son sens est √† ", end="")
    #on finit par afficher le sens de notre fl√®che
    if nbSommetsDroite>nbSommetsGauche:
        print('Droite')
    else:
        print('Gauche')


    #les prochaines lignes ne servent qu'√† l'affichage graphique
    cv2.imshow('Fl√®che trouv√©e !',img)
    cv2.waitKey(0)

try:
    #! Prendre une photo depuis la webcam
    camera = cv2.VideoCapture(0)
    x, image = camera.read()
    cv2.imwrite('opencv1.png', image)

    #!trouve 4 ARuco avec le m√™me identifiant dans l‚Äôimage, sinon renvoie une erreur
    dictionnaire = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_250)
    parametres =  cv2.aruco.DetectorParameters()
    coinsMarqueurs, idsMarqueur, PotentielsMarqueurs = cv2.aruco.ArucoDetector(dictionnaire, parametres).detectMarkers(cv2.imread('opencv1.png'))

    print("üì° Recherche des 4 ARuco avec le m√™me identifiant ...")
    animation = "|||||/////-----\\\\\\"
    i = 0
    while True:
        if idsMarqueur is not None and len(coinsMarqueurs) == 4 and len(set(idsMarqueur.flatten())) == 1:
            cv2.imwrite('opencv1.png', image)
            break

        x, image = camera.read()
        coinsMarqueurs, idsMarqueur, PotentielsMarqueurs = cv2.aruco.ArucoDetector(dictionnaire, parametres).detectMarkers(image)
        

        # Arr√™t au bout de 10 secondes sans d√©tection
        if i == 333:
            print("üö´ Erreur : pas assez d'arucos d√©tect√©s ou de m√™me identifiant ! (Delay10sOutofBounds)")
            exit()

        # Print the animation
        print(animation[i % len(animation)], end="\r")
        i += 1
        sys.stdout.flush()
        time.sleep(0.01)
    print('\r' + ' ' * len(animation) + '\r', end='')
    print("‚úÖ 4 Arucos avec le m√™me identifiant trouv√©s !")



    #? Afficher les coins des arucos d√©tect√©s
    ids = idsMarqueur.flatten()	
    image = cv2.imread('opencv1.png')
    tous_coins = []
    for (coinMarqueur, idMarqueur) in zip(coinsMarqueurs, ids):
        # extraire les angles des aruco (toujours dans l'ordre haut-gauche, haut-droite, bas-gauche, bas-droit)
        coins = coinMarqueur.reshape((4, 2))
        (topLeft, topRight, bottomRight, bottomLeft) = coins
        # convertir en entier (pour l'affichage)
        topRight = (int(topRight[0]), int(topRight[1]))
        bottomRight = (int(bottomRight[0]), int(bottomRight[1]))
        bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))
        topLeft = (int(topLeft[0]), int(topLeft[1]))
        
        # dessiner un quadrilat√®re autour de chaque aruco
        cv2.line(image, topLeft, topRight, (0, 255, 0), 2)
        cv2.line(image, topRight, bottomRight, (0, 255, 0), 2)
        cv2.line(image, bottomRight, bottomLeft, (0, 255, 0), 2)
        cv2.line(image, bottomLeft, topLeft, (0, 255, 0), 2)
        # calculer puis afficher un point rouge au centre
        cX = int((topLeft[0] + bottomRight[0]) / 2.0)
        cY = int((topLeft[1] + bottomRight[1]) / 2.0)
        cv2.circle(image, (cX, cY), 4, (0, 0, 255), -1)
        # affiher l'identifiant
        cv2.putText(image, str(idMarqueur),
            (topLeft[0], topLeft[1] - 15), cv2.FONT_HERSHEY_SIMPLEX,
            0.5, (0, 255, 0), 2)
        
        tous_coins.append(coins)
        
    # afficher l'image
    cv2.imshow("D√©tection des arucos sur l'image", image)
    cv2.waitKey(0)

    #! D√©former l‚Äôimage pour ne travailler que dans la zone d‚Äôint√©r√™t d√©finie par ces 4 marqueurs
    print("üîç On zoom sur l'image dans la zone des 4 marqueurs")
    image = cv2.imread('opencv1.png')
    tous_coins = np.concatenate(tous_coins)
    # On calcule les coordonn√©es des coins de l'image zoom√©e
    top_left = np.min(tous_coins, axis=0)
    bottom_right = np.max(tous_coins, axis=0)
    top_right = np.array([bottom_right[0], top_left[1]])
    bottom_left = np.array([top_left[0], bottom_right[1]])

    # On sp√©cifie les coordonn√©es des coins de l'image zoom√©e
    points1 = np.float32([top_left + [20, 20], top_right + [-20, 20], bottom_right + [-20, -20], bottom_left + [20, -20]])
    points2 = np.float32([[0, 0], [200, 0], [200, 200], [0, 200]])

    # On calcule la matrice de transformation
    vecttrans = cv2.getPerspectiveTransform(points1, points2)

    # On applique la transformation √† l'image d'origine
    image_zoomee = cv2.warpPerspective(image, vecttrans, (200, 200))

    # On affiche l'image zoom√©e
    cv2.imshow("Zoom sur la zone", image_zoomee)
    cv2.imwrite('image_zoomee.png', image_zoomee)
    cv2.waitKey(0)

    #! Recherche d'une fl√®che dans l'image zoom√©e et d√©termination de son sens
    if idsMarqueur[0] == 13: #? L'ID de la fl√®che est 13
        print("üîç On recherche une fl√®che dans l'image zoom√©e")
        trouver_fleche_et_son_sens()
    if idsMarqueur[0] == 8: #? L'ID des rectangles de couleur est 8
        print("ü§î Il devrait y avoir un rectangle de couleur dans la zone zoom√©e")
except Exception as e:
    print("üö´ Erreur :", e)